# Redis

## Redis 数据结构

|               |                               |                                                              |
| ------------- | ----------------------------- | ------------------------------------------------------------ |
| Redis数据结构 | 底层实现                      | 应用场景                                                     |
| `String`      | 整数（只有 long 类型） 或 SDS | 二进制安全，缓存静态文件、用作计数器（incr），统计次数（如网站访问）。 |
| `Hash`        | 字典 或 压缩列表              | 存储对象，用户信息、商品信息等。                             |
| `List`        | 双端链表 或 压缩列表 或 快表  | 消息队列、粉丝列表、关注列表等。                             |
| `Set`         | 字典 或 整数集合              | 用于去重相关操作                                             |
| `ZSet`        | 字典 或 压缩列表              | 在`Set`功能的基础之外，构建优先队列。                        |
| HyperLoglog   |                               | 基数统计                                                     |
| BloomFilter   |                               | 大数据判断是否存在、解决缓存穿透、爬虫/邮箱等系统的过滤。    |
| GeoHash       |                               | 地里定位，附近的人、附近的 xxx                               |
| bitMap        |                               |                                                              |
| Pub/Sub       |                               |                                                              |
| Stream        |                               |                                                              |

## Redis数据结构原理

1、在 Redis 中， 一个字符串对象除了可以保存字符串值之外，还可以保存 `long` 类型的值，当字符串对象保存的是字符串时，它包含的才是 sds 值，否则的话，它就是一个 `long` 类型的值

```c
typedef char *sds;
struct sdshdr {
    // buf 已占用长度 
    int len;
    // buf 剩余可用长度 
    int free;
    // 实际保存字符串数据的地方
    char buf[]; 
};
```

2、双端链表作为一种通用的数据结构，在 Redis 内部使用得非常多:它既是 Redis `列表结构`的底层实现之一，还被大量 Redis 模块所使用，用于构建 Redis 的其他功能，双端链表还被很多 Redis 内部模块所应用:

- 事务模块使用双端链表来按顺序保存输入的命令;
- 服务器模块使用双端链表来保存多个客户端;
- 订阅/发送模块使用双端链表来保存订阅模式的多个客户端;
- 事件模块使用双端链表来保存时间事件(time event).



## 跳跃表

### 为什么使用跳跃表

首先，因为 zset 要支持随机的插入和删除，所以它 **不宜使用数组来实现**，关于排序问题，我们也很容易就想到 **红黑树/ 平衡树** 这样的树形结构，为什么 Redis 不使用这样一些结构呢？

1. **性能考虑：** 在高并发的情况下，树形结构需要执行一些类似于 rebalance 这样的可能涉及整棵树的操作，相对来说跳跃表的变化只涉及局部 *(下面详细说)*；
2. **实现考虑：** 在复杂度与红黑树相同的情况下，跳跃表实现起来更简单，看起来也更加直观；

基于以上的一些考虑，Redis 基于 **William Pugh** 的论文做出一些改进后采用了 **跳跃表** 这样的结构。

### 本质是解决查找问题

我们先来看一个普通的链表结构：

![图片](https://mmbiz.qpic.cn/mmbiz_png/ia1kbU3RS1H5ZLiaicqeR9mzkQuQLwvtFfQJ2WzK4Dj4ibLKst3qkVLjMQcy5FkqLu7pmHhvoH15H5JUmIsBjicdhvw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

我们需要这个链表按照 score 值进行排序，这也就意味着，当我们需要添加新的元素时，我们需要定位到插入点，这样才可以继续保证链表是有序的，通常我们会使用 **二分查找法**，但二分查找是有序数组的，链表没办法进行位置定位，我们除了遍历整个找到第一个比给定数据大的节点为止 *（时间复杂度 O(n))* 似乎没有更好的办法。

但假如我们每相邻两个节点之间就增加一个指针，让指针指向下一个节点，如下图：

![图片](https://mmbiz.qpic.cn/mmbiz_png/ia1kbU3RS1H5ZLiaicqeR9mzkQuQLwvtFfQZYuqmprbyribHqEdWvMKjdeiaaUR5swWG3iciaJ2ghlwp6ubdfxLahIQVg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

这样所有新增的指针连成了一个新的链表，但它包含的数据却只有原来的一半 *（图中的为 3，11）*。

现在假设我们想要查找数据时，可以根据这条新的链表查找，如果碰到比待查找数据大的节点时，再回到原来的链表中进行查找，比如，我们想要查找 7，查找的路径则是沿着下图中标注出的红色指针所指向的方向进行的：

![图片](https://mmbiz.qpic.cn/mmbiz_png/ia1kbU3RS1H5ZLiaicqeR9mzkQuQLwvtFfQn3GcsgglqK0DaME5KXiciaQLCkkSVKMia9gmv5icavhQhOwuHRavTLIMdg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

这是一个略微极端的例子，但我们仍然可以看到，通过新增加的指针查找，我们不再需要与链表上的每一个节点逐一进行比较，这样改进之后需要比较的节点数大概只有原来的一半。

利用同样的方式，我们可以在新产生的链表上，继续为每两个相邻的节点增加一个指针，从而产生第三层链表：

![图片](https://mmbiz.qpic.cn/mmbiz_png/ia1kbU3RS1H5ZLiaicqeR9mzkQuQLwvtFfQZxrtjNvic9S9GPVcQiaWS4dhxvCJPxdHSxSCUdP81SU5o6JjS0E9sy5A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

在这个新的三层链表结构中，我们试着 **查找 13**，那么沿着最上层链表首先比较的是 11，发现 11 比 13 小，于是我们就知道只需要到 11 后面继续查找，**从而一下子跳过了 11 前面的所有节点。**

可以想象，当链表足够长，这样的多层链表结构可以帮助我们跳过很多下层节点，从而加快查找的效率。

### 更进一步的跳跃表

**跳跃表 skiplist** 就是受到这种多层链表结构的启发而设计出来的。按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到 *O(logn)*。

但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的 2:1 的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点 *（也包括新插入的节点）* 重新进行调整，这会让时间复杂度重新蜕化成 *O(n)*。删除数据也有同样的问题。

![图片](https://mmbiz.qpic.cn/mmbiz_png/ia1kbU3RS1H5ZLiaicqeR9mzkQuQLwvtFfQ5qUqf8c0vC3bfbc710Tz6iadcOlDYb39pApOUP9pCaUDQtuicUn9Jibvg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

从上面的创建和插入的过程中可以看出，每一个节点的层数（level）是随机出来的，而且新插入一个节点并不会影响到其他节点的层数，因此，**插入操作只需要修改节点前后的指针，而不需要对多个节点都进行调整**，这就降低了插入操作的复杂度。

**Redis 跳跃表默认允许最大的层数是 ZSKIPLIST_MAXLEVEL = 32**



## Redis 内存回收策略

- `volatile-lru`：从已设置过期时间的数据集（`server.db[i].expires`）中挑选最久未使用的数据淘汰；
- `volatile-ttl`：从已设置过期时间的数据集（`server.db[i].expires`）中挑选将要过期的数据淘汰；
- `volatile-random`：从已设置过期时间的数据集（`server.db[i].expires`）中随机选取数据淘汰；
- `allkeys-lru`：当内存不足以容纳新写入数据时，在键空间中，移除最久未使用的 `key`；
- `allkeys-random`：从数据集（`server.db[i].dict`）中随机选取数据淘汰；
- `no-eviction`：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。

`volatile-xxx` 这三个淘汰策略使用的不是全量数据，有可能无法淘汰出足够的内存空间。在没有过期键或者没有设置超时属性的键的情况下，这三种策略和 `noeviction` 差不多。

4.0 版本后增加以下两种：

- `volatile-lfu`：从已设置过期时间的数据集(`server.db[i].expires`)中挑选最不经常使用的数据淘汰。
- `allkeys-lfu`：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 `key`。

一般的经验规则：

- 使用 `allkeys-lru` 策略：当预期请求符合一个幂次分布(二八法则等)，比如一部分的子集元素比其它元素被访问的更多时，可以选择这个策略。
- 使用 `allkeys-random` 策略：循环连续的访问所有的键时，或者预期请求分布平均（所有元素被访问的概率都差不多）。
- 使用 `volatile-ttl`：要采取这个策略，缓存对象的 `TTL` 值最好有差异。

`volatile-lru` 和 `volatile-random` 策略，当想要使用**单一**的 `Redis` 实例来同时实现**缓存淘汰和持久化**一些经常使用的键集合时很有用。

- 对未设置过期时间的键进行持久化保存，对设置了过期时间的键参与缓存淘汰。
- 不过一般运行两个实例是解决这个问题的更好方法。

为键设置过期时间也是需要消耗内存的，所以使用 `allkeys-lru` 这种策略更加节省空间，因为这种策略下可以不为键设置过期时间。

##  **过期键的删除策略**有两种：

- 惰性删除：每次从键空间获取键时，都检查键是否过期，如果过期的话就删除该键，否则返回该键。
- 定期删除：每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键。

## **Redis LRU 配置参数：**

- `maxmemory`：配置 `Redis` 存储数据时指定限制的内存大小，比如 `100m`。当缓存消耗的内存超过这个数值时, 将触发数据淘汰。该数据配置为 00 时，表示缓存的数据量没有限制, 即 LRULRU 功能不生效。6464 位的系统默认值为 00，3232 位的系统默认内存限制为 3GB3GB。
- `maxmemory_policy`：触发数据淘汰后的淘汰策略。
- `maxmemory_samples`：随机采样的精度，也就是随即取出 keykey 的数目。该数值配置越大, 越接近于真实的 LRULRU 算法，但是数值越大，相应消耗也变高，对性能有一定影响，样本值默认为 55 。

## 分布式锁实现与分析

### SETNX实现的分布式锁

```she
# 将key设置值为value，如果key不存在，这种情况下等同SET命令。 当key存在时，什么也不做，SET if Not eXists
SETNX key value
```

#### 加锁步骤

1. `SETNX lock.foo <current Unix time + lock timeout + 1>`

   如果客户端获得锁，`SETNX`返回`1`，加锁成功。

   如果`SETNX`返回`0`，那么该键已经被其他的客户端锁定。

2. 接上一步，`SETNX`返回`0`加锁失败，此时，调用`GET lock.foo`获取时间戳检查该锁是否已经过期：

   - 如果没有过期，则休眠一会重试。

   - 如果已经过期，则可以获取该锁。具体的：调用`GETSET lock.foo <current Unix timestamp + lock timeout + 1>`基于当前时间设置新的过期时间。

     **注意**: 这里设置的时候因为在`SETNX`与`GETSET`之间有个窗口期，在这期间锁可能已被其他客户端抢去，所以这里需要判断`GETSET`的返回值，他的返回值是SET之前旧的时间戳：

     - 若旧的时间戳已过期，则表示加锁成功。
     - 若旧的时间戳还未过期（说明被其他客户端抢去并设置了时间戳），代表加锁失败，需要等待重试。

#### 解锁步骤

解锁相对简单，只需`GET lock.foo`时间戳，判断是否过期，过期就调用删除`DEL lock.foo`



### SET实现的分布式锁

```shell
SET key value [EX seconds|PX milliseconds] [NX|XX]
```

#### 加锁步骤

一条命令即可加锁: `SET resource_name my_random_value NX PX 30000`

这个命令只有当`key` 对应的键不存在resource_name时（NX选项的作用）才生效，同时设置30000毫秒的超时，成功设置其值为my_random_value，这是个在所有redis客户端加锁请求中全局唯一的随机值。

#### 解锁步骤

解锁时需要确保my_random_value和加锁的时候一致。下面的Lua脚本可以完成

```lau
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

这段Lua脚本在执行的时候要把前面的`my_random_value`作为`ARGV[1]`的值传进去，把`resource_name`作为`KEYS[1]`的值传进去。释放锁其实包含三步操作：’GET’、判断和’DEL’，用Lua脚本来实现能保证这三步的原子性。



### Redis集群分布式锁Redlock

前面两种分布式锁的实现都是针对单redis master实例，既不是有互为备份的slave节点也不是多master集群，如果是redis集群，每个redis master节点都是独立存储，这种场景用前面两种加锁策略有锁的安全性问题。

比如下面这种场景：

> 1. 客户端1从Master获取了锁。
> 2. Master宕机了，存储锁的key还没有来得及同步到Slave上。
> 3. Slave升级为Master。
> 4. 客户端2从新的Master获取到了对应同一个资源的锁。
>
> 于是，客户端1和客户端2同时持有了同一个资源的锁。锁的安全性被打破。

针对这种多redis服务实例的场景，redis作者antirez设计了**Redlock**

#### 加锁步骤

集群加锁的总体思想是尝试锁住所有节点，当有一半以上节点被锁住就代表加锁成功。集群部署你的数据可能保存在任何一个redis服务节点上，一旦加锁必须确保集群内任意节点被锁住，否则也就失去了加锁的意义。

1. 获取当前时间（毫秒数）。
2. 按顺序依次向N个Redis节点执行**获取锁**的操作。这个获取操作跟前面基于单Redis节点的**获取锁**的过程相同，包含随机字符串`my_random_value`，也包含过期时间(比如`PX 30000`，即锁的有效时间)。为了保证在某个Redis节点不可用的时候算法能够继续运行，这个**获取锁**的操作还有一个超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个Redis节点获取锁失败以后，应该立即尝试下一个Redis节点。这里的失败，应该包含任何类型的失败，比如该Redis节点不可用，或者该Redis节点上的锁已经被其它客户端持有（注：Redlock原文中这里只提到了Redis节点不可用的情况，但也应该包含其它的失败情况）。
3. 计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数Redis节点（>= N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间(lock validity time)，那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败。
4. 如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间。
5. 如果最终获取锁失败了（可能由于获取到锁的Redis节点个数少于N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有Redis节点发起**释放锁**的操作（即前面介绍的Redis Lua脚本）。

#### 解锁步骤

客户端向所有Redis节点发起释放锁的操作，不管这些节点当时在获取锁的时候成功与否。



## Redis分布式锁的缺陷

**1、 redis服务器时钟漂移问题**

如果redis服务器的机器时钟发生了向前跳跃，就会导致这个key过早超时失效，比如说客户端1拿到锁后，key的过期时间是12:02分，但redis服务器本身的时钟比客户端快了2分钟，导致key在12:00的时候就失效了，这时候，如果客户端1还没有释放锁的话，就可能导致多个客户端同时持有同一把锁的问题。

**2、节点发生崩溃重启的话，还是有可能出现多个客户端同时获取锁的情况**

假设一共有5个Redis节点：A、B、C、D、E，客户端1和2分别加锁

1. 客户端1成功锁住了A，B，C，获取锁成功（但D和E没有锁住）。
2. 节点C的master挂了，然后锁还没同步到slave，slave升级为master后丢失了客户端1加的锁。
3. 客户端2这个时候获取锁，锁住了C，D，E，获取锁成功。

> 总结

鱼和熊掌不可兼得，之所以用Redis作为分布式锁的工具，很大程度上是因为Redis本身效率高且单进程的特点，即使在高并发的情况下也能很好的保证性能，但很多时候，性能和安全不能完全兼顾，如果你一定要保证锁的安全性的话，可以用其他的中间件如db、zookeeper来做控制，这些工具能很好的保证锁的安全，但性能方面只能说是差强人意
